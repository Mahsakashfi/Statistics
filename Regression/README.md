# Regression Learning Path – 6 Weeks
This repository documents a structured 6-week journey to learn regression from the foundations to modern machine-learning methods. Each week includes a focused topic, a dataset, practical exercises, and a Jupyter notebook.
# Weekly Overview
# *Week 1 – Simple Linear Regression*
Hours vs. Scores dataset
Scatter plot, regression line, residuals
Slope, intercept, R²
# *Week 2 – Multiple Linear Regression*
Several predictors
Dummy variables, VIF
Train–test split and model interpretation
# *Week 3 – Regression Assumptions & Diagnostics*
Linearity, normality, homoscedasticity
Residual plots, Q–Q plots, outliers
Fixing violations
# *Week 4 – Logistic Regression*
Binary outcomes
Sigmoid function, odds ratios
Confusion matrix, ROC–AUC
# *Week 5 – Regularized Regression*
Ridge, Lasso, Elastic Net
Overfitting control
Cross-validation and hyperparameter tuning
# *Week 6 – ML Regression Models*
Decision Trees, Random Forest, Gradient Boosting
Feature importance
Model comparison (RMSE, MAE, R²)
